{
    "algorithm": "TD7",
    "load_q": false,
    "load_policy": false,
    "render": false,
    "algorithm_kwargs": {
      "batch_size": 128,
      "max_path_length": 500,
      "min_num_steps_before_training": 3300,
      "num_epochs": 2000,
      "num_eval_steps_per_epoch": 500,
      "num_expl_steps_per_train_loop": 2500,
      "num_trains_per_train_loop": 1000,
      "pre_training": false
    },
    "hyperparameters": {},
    "environment_kwargs": {
      "control_freq": 20,
      "controller": "GH360T_EQUILIBRIUM_POINT_SOFT",
      "controller_config": {
        "tendon_noise": false,
        "motor_move_sim": false
      },
      "motor_obs": true,
      "q_vel_obs": true,
      "env_name": "TrajectoryFollowing",
      "force_punishment": false,
      "task_state_obs": false,
      "via_point_cnt": 1,
      "fixed_quadrants": false,
      "hard_reset": false,
      "horizon": 500,
      "ignore_done": true,
      "reward_scale": 1.0,
      "gripper_types": "HookGripper",
      "robots": [
        "GH360T"
      ]
    },
    "policy_kwargs": {
      "hidden_sizes": [
        256,
        256
      ]
    },
    "qf_kwargs": {
      "hidden_sizes": [
        256,
        256
      ]
    },
    "replay_buffer_size": 1000000,
    "seed": 7,
    "offline": false,
    "trainer_kwargs": {
      "discount": 0.99,
      "policy_lr": 0.001,
      "qf_lr": 0.0003,
      "reward_scale": 1.0,
      "soft_target_tau": 0.005,
      "target_update_period": 5,
      "use_automatic_entropy_tuning": true
    },
    "version": "normal"
  }